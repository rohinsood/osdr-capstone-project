{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['th_positive_cells', 'repo_glial_cells']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"filtered_data.csv\")\n",
    "results_df = pd.DataFrame(columns=['Model', 'Target Variable', 'MSE', 'RMSE', 'MAE', 'R2', 'R', 'Selected Features'])\n",
    "df.drop(columns=df.columns[0], inplace=True)\n",
    "target_columns = df.columns[-2:].to_list()\n",
    "target_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>th_positive_cells</th>\n",
       "      <th>repo_glial_cells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>93.330128</td>\n",
       "      <td>479.387401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.666919</td>\n",
       "      <td>126.026996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>276.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>83.750000</td>\n",
       "      <td>397.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>95.500000</td>\n",
       "      <td>455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>103.500000</td>\n",
       "      <td>537.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>792.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       th_positive_cells  repo_glial_cells\n",
       "count          24.000000         24.000000\n",
       "mean           93.330128        479.387401\n",
       "std            16.666919        126.026996\n",
       "min            51.000000        276.000000\n",
       "25%            83.750000        397.750000\n",
       "50%            95.500000        455.000000\n",
       "75%           103.500000        537.250000\n",
       "max           120.000000        792.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_variables = df[target_columns]\n",
    "target_variables.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MLP_and_store_results(data, target_column, n_features=50):\n",
    "    # Prepare the dataset\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    \n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Feature selection using RFE\n",
    "    selector = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=n_features, step=10)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "    \n",
    "    # Select the important features\n",
    "    X_train_selected = selector.transform(X_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "    X_test_scaled = scaler.transform(X_test_selected)\n",
    "    \n",
    "    # Build and train the MLP model\n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(64, 32, 16), max_iter=200, random_state=42)\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = mlp.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r = np.sqrt(r2)\n",
    "    \n",
    "    # Get the selected feature names\n",
    "    selected_features = X.columns[selector.support_]\n",
    "    \n",
    "    # Store the results in the DataFrame\n",
    "    results_df.loc[len(results_df)] = [\"ANN\", target_column, mse, rmse, mae, r2, r, ','.join(selected_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LR_and_store_results(data, target_column, n_features=50):\n",
    "    # Prepare the dataset\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    \n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Feature selection using RFE\n",
    "    selector = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=n_features, step=10)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "    \n",
    "    # Select the important features\n",
    "    X_train_selected = selector.transform(X_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "    X_test_scaled = scaler.transform(X_test_selected)\n",
    "    \n",
    "    # Build and train the Linear Regression model\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = lr.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r = np.sqrt(r2)\n",
    "    \n",
    "    # Get the selected feature names\n",
    "    selected_features = X.columns[selector.support_]\n",
    "    \n",
    "    # Store the results in the DataFrame\n",
    "    results_df.loc[len(results_df)] = [\"Linear Regression\", target_column, mse, rmse, mae, r2, r, ','.join(selected_features)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate a Random Forest model\n",
    "def train_RF_and_store_results(data, target_column, n_features=50):\n",
    "    # Prepare the dataset\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    \n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Feature selection using RFE\n",
    "    selector = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=n_features, step=10)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "    \n",
    "    # Select the important features\n",
    "    X_train_selected = selector.transform(X_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "    X_test_scaled = scaler.transform(X_test_selected)\n",
    "    \n",
    "    # Build and train the Random Forest model\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = rf.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r = np.sqrt(r2)\n",
    "    \n",
    "    # Get the selected feature names\n",
    "    selected_features = X.columns[selector.support_]\n",
    "    \n",
    "    # Store the results in the DataFrame\n",
    "    results_df.loc[len(results_df)] = [\"Random Forest\", target_column, mse, rmse, mae, r2, r, ','.join(selected_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP for th_positive_cells...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1828/172558715.py:32: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression for th_positive_cells...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1828/1024327637.py:32: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest for th_positive_cells...\n",
      "Training MLP for repo_glial_cells...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1828/172558715.py:32: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression for repo_glial_cells...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1828/1024327637.py:32: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest for repo_glial_cells...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1828/3630538396.py:33: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the models\n",
    "for target in target_columns:\n",
    "    print(f\"Training MLP for {target}...\")\n",
    "    train_MLP_and_store_results(df, target, n_features=5000)\n",
    "    print(f\"Training Linear Regression for {target}...\")\n",
    "    train_LR_and_store_results(df, target, n_features=5000)\n",
    "    print(f\"Training Random Forest for {target}...\")\n",
    "    train_RF_and_store_results(df, target, n_features=5000)\n",
    "    \n",
    "results_csv_path = 'n5000_model_results.csv'\n",
    "results_df.to_csv(results_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Target Variable</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>R</th>\n",
       "      <th>Selected Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>th_positive_cells</td>\n",
       "      <td>1062.492</td>\n",
       "      <td>32.596</td>\n",
       "      <td>30.189</td>\n",
       "      <td>-7.926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>th_positive_cells</td>\n",
       "      <td>5557.021</td>\n",
       "      <td>74.545</td>\n",
       "      <td>39.357</td>\n",
       "      <td>-45.682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>th_positive_cells</td>\n",
       "      <td>144.416</td>\n",
       "      <td>12.017</td>\n",
       "      <td>9.704</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANN</td>\n",
       "      <td>repo_glial_cells</td>\n",
       "      <td>32987.003</td>\n",
       "      <td>181.623</td>\n",
       "      <td>145.480</td>\n",
       "      <td>-2.359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>repo_glial_cells</td>\n",
       "      <td>231656.042</td>\n",
       "      <td>481.307</td>\n",
       "      <td>353.874</td>\n",
       "      <td>-22.588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>repo_glial_cells</td>\n",
       "      <td>18640.642</td>\n",
       "      <td>136.531</td>\n",
       "      <td>112.600</td>\n",
       "      <td>-0.898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model    Target Variable        MSE    RMSE     MAE      R2  \\\n",
       "0                ANN  th_positive_cells   1062.492  32.596  30.189  -7.926   \n",
       "1  Linear Regression  th_positive_cells   5557.021  74.545  39.357 -45.682   \n",
       "2      Random Forest  th_positive_cells    144.416  12.017   9.704  -0.213   \n",
       "3                ANN   repo_glial_cells  32987.003 181.623 145.480  -2.359   \n",
       "4  Linear Regression   repo_glial_cells 231656.042 481.307 353.874 -22.588   \n",
       "5      Random Forest   repo_glial_cells  18640.642 136.531 112.600  -0.898   \n",
       "\n",
       "    R                                  Selected Features  \n",
       "0 NaN  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "1 NaN  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "2 NaN  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "3 NaN  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "4 NaN  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "5 NaN  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
