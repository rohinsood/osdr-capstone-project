{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/datasets/augmented_data.csv\")\n",
    "results_df = pd.DataFrame(columns=['Model', 'Target Variable', 'Training Environment', 'Test Environment', 'MSE', 'RMSE', 'MAE', 'R2', 'R', 'Selected Features'])\n",
    "df.drop(columns=df.columns[0], inplace=True)\n",
    "target_columns = df.columns[-2:].to_list()\n",
    "\n",
    "# Extract environments from source_name\n",
    "df['Environment'] = df['source_name'].apply(lambda x: x.split('_')[0])\n",
    "environments = df['Environment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>th_positive_cells</th>\n",
       "      <th>repo_glial_cells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.536048</td>\n",
       "      <td>212.528303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>44.903146</td>\n",
       "      <td>252.787051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.857618</td>\n",
       "      <td>-1.384246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.624973</td>\n",
       "      <td>6.227505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.049876</td>\n",
       "      <td>22.278411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.500000</td>\n",
       "      <td>454.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>792.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       th_positive_cells  repo_glial_cells\n",
       "count          96.000000         96.000000\n",
       "mean           42.536048        212.528303\n",
       "std            44.903146        252.787051\n",
       "min            -1.857618         -1.384246\n",
       "25%             4.624973          6.227505\n",
       "50%            10.049876         22.278411\n",
       "75%            92.500000        454.000000\n",
       "max           120.000000        792.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_variables = df[target_columns]\n",
    "target_variables.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MLP_and_store_results(data, target_column, n_features=50):\n",
    "    for e_train in environments:\n",
    "        \n",
    "        print(\"Training environment:\", e_train)\n",
    "        \n",
    "        train_data = data[data['Environment'] == e_train]\n",
    "        \n",
    "        X_train = train_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "        y_train = train_data[target_column]\n",
    "        \n",
    "        # Feature selection using RFE\n",
    "        selector = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=n_features, step=10)\n",
    "        selector = selector.fit(X_train, y_train)\n",
    "        \n",
    "        # Select the important features\n",
    "        X_train_selected = selector.transform(X_train)\n",
    "        \n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "        \n",
    "        # Build and train the MLP model\n",
    "        mlp = MLPRegressor(hidden_layer_sizes=(64, 32, 16), max_iter=400, random_state=42)\n",
    "        mlp.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate the model on other environments\n",
    "        for e_test in environments:\n",
    "            \n",
    "            print(\"Testing environment:\", e_train)\n",
    "            if (e_test == e_train) or (len(data[data['Environment'] == e_test]) == 0):\n",
    "                continue\n",
    "            \n",
    "            test_data = data[data['Environment'] == e_test]\n",
    "            X_test = test_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "            y_test = test_data[target_column]\n",
    "            \n",
    "            X_test_selected = selector.transform(X_test)\n",
    "            X_test_scaled = scaler.transform(X_test_selected)\n",
    "            \n",
    "            y_pred = mlp.predict(X_test_scaled)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            r = np.sqrt(r2)\n",
    "            \n",
    "            # Get the selected feature names\n",
    "            selected_features = X_train.columns[selector.support_]\n",
    "            \n",
    "            # Store the results in the DataFrame\n",
    "            results_df.loc[len(results_df)] = [\"ANN\", target_column, e_train, e_test, mse, rmse, mae, r2, r, ','.join(selected_features)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LR_and_store_results(data, target_column, n_features=50):\n",
    "    for e_train in environments:\n",
    "        train_data = data[data['Environment'] == e_train]\n",
    "        \n",
    "        X_train = train_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "        y_train = train_data[target_column]\n",
    "        \n",
    "        # Feature selection using RFE\n",
    "        selector = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=n_features, step=10)\n",
    "        selector = selector.fit(X_train, y_train)\n",
    "        \n",
    "        # Select the important features\n",
    "        X_train_selected = selector.transform(X_train)\n",
    "        \n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "        \n",
    "        # Build and train the Linear Regression model\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate the model on other environments\n",
    "        for e_test in environments:\n",
    "            if e_test == e_train:\n",
    "                continue\n",
    "            \n",
    "            test_data = data[data['Environment'] == e_test]\n",
    "            X_test = test_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "            y_test = test_data[target_column]\n",
    "            \n",
    "            X_test_selected = selector.transform(X_test)\n",
    "            X_test_scaled = scaler.transform(X_test_selected)\n",
    "            \n",
    "            y_pred = lr.predict(X_test_scaled)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            r = np.sqrt(r2)\n",
    "            \n",
    "            # Get the selected feature names\n",
    "            selected_features = X_train.columns[selector.support_]\n",
    "            \n",
    "            # Store the results in the DataFrame\n",
    "            results_df.loc[len(results_df)] = [\"Linear Regression\", target_column, e_train, e_test, mse, rmse, mae, r2, r, ','.join(selected_features)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RF_and_store_results(data, target_column, n_features=50):\n",
    "    for e_train in environments:\n",
    "        train_data = data[data['Environment'] == e_train]\n",
    "        \n",
    "        X_train = train_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "        y_train = train_data[target_column]\n",
    "        \n",
    "        # Feature selection using RFE\n",
    "        selector = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=n_features, step=10)\n",
    "        selector = selector.fit(X_train, y_train)\n",
    "        \n",
    "        # Select the important features\n",
    "        X_train_selected = selector.transform(X_train)\n",
    "        \n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "        \n",
    "        # Build and train the Random Forest model\n",
    "        rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        rf.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate the model on other environments\n",
    "        for e_test in environments:\n",
    "            if e_test == e_train:\n",
    "                continue\n",
    "            \n",
    "            test_data = data[data['Environment'] == e_test]\n",
    "            X_test = test_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "            y_test = test_data[target_column]\n",
    "            \n",
    "            X_test_selected = selector.transform(X_test)\n",
    "            X_test_scaled = scaler.transform(X_test_selected)\n",
    "            \n",
    "            y_pred = rf.predict(X_test_scaled)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            r = np.sqrt(r2)\n",
    "            \n",
    "            # Get the selected feature names\n",
    "            selected_features = X_train.columns[selector.support_]\n",
    "            \n",
    "            # Store the results in the DataFrame\n",
    "            results_df.loc[len(results_df)] = [\"Random Forest\", target_column, e_train, e_test, mse, rmse, mae, r2, r, ','.join(selected_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_and_store_results(data, target_column, n_features=50):\n",
    "    for e_train in environments:\n",
    "        train_data = data[data['Environment'] == e_train]\n",
    "        \n",
    "        X_train = train_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "        y_train = train_data[target_column]\n",
    "        \n",
    "        # Feature selection using RFE\n",
    "        selector = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=n_features, step=10)\n",
    "        selector = selector.fit(X_train, y_train)\n",
    "        \n",
    "        # Select the important features\n",
    "        X_train_selected = selector.transform(X_train)\n",
    "        \n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "        \n",
    "        # Build and train the Logistic Regression model\n",
    "        model = LogisticRegression(max_iter=200, random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate the model on other environments\n",
    "        for e_test in environments:\n",
    "            if e_test == e_train:\n",
    "                continue\n",
    "            \n",
    "            test_data = data[data['Environment'] == e_test]\n",
    "            X_test = test_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "            y_test = test_data[target_column]\n",
    "            \n",
    "            X_test_selected = selector.transform(X_test)\n",
    "            X_test_scaled = scaler.transform(X_test_selected)\n",
    "            \n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            r = np.sqrt(r2)\n",
    "            \n",
    "            # Get the selected feature names\n",
    "            selected_features = X_train.columns[selector.support_]\n",
    "            \n",
    "            # Store the results in the DataFrame\n",
    "            results_df.loc[len(results_df)] = [\"Logistic Regression\", target_column, e_train, e_test, mse, rmse, mae, r2, r, ','.join(selected_features)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ridge_and_store_results(data, target_column, n_features=50):\n",
    "    for e_train in environments:\n",
    "        train_data = data[data['Environment'] == e_train]\n",
    "        \n",
    "        X_train = train_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "        y_train = train_data[target_column]\n",
    "        \n",
    "        # Feature selection using RFE\n",
    "        selector = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=n_features, step=10)\n",
    "        selector = selector.fit(X_train, y_train)\n",
    "        \n",
    "        # Select the important features\n",
    "        X_train_selected = selector.transform(X_train)\n",
    "        \n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "        \n",
    "        # Build and train the Ridge Regression model\n",
    "        model = Ridge(random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate the model on other environments\n",
    "        for e_test in environments:\n",
    "            if e_test == e_train:\n",
    "                continue\n",
    "            \n",
    "            test_data = data[data['Environment'] == e_test]\n",
    "            X_test = test_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "            y_test = test_data[target_column]\n",
    "            \n",
    "            X_test_selected = selector.transform(X_test)\n",
    "            X_test_scaled = scaler.transform(X_test_selected)\n",
    "            \n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            r = np.sqrt(r2)\n",
    "            \n",
    "            # Get the selected feature names\n",
    "            selected_features = X_train.columns[selector.support_]\n",
    "            \n",
    "            # Store the results in the DataFrame\n",
    "            results_df.loc[len(results_df)] = [\"Ridge Regression\", target_column, e_train, e_test, mse, rmse, mae, r2, r, ','.join(selected_features)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lasso_and_store_results(data, target_column, n_features=50):\n",
    "    for e_train in environments:\n",
    "        train_data = data[data['Environment'] == e_train]\n",
    "        \n",
    "        X_train = train_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "        y_train = train_data[target_column]\n",
    "        \n",
    "        # Feature selection using RFE\n",
    "        selector = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=n_features, step=10)\n",
    "        selector = selector.fit(X_train, y_train)\n",
    "        \n",
    "        # Select the important features\n",
    "        X_train_selected = selector.transform(X_train)\n",
    "        \n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "        \n",
    "        # Build and train the Lasso Regression model\n",
    "        model = Lasso(random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate the model on other environments\n",
    "        for e_test in environments:\n",
    "            if e_test == e_train:\n",
    "                continue\n",
    "            \n",
    "            test_data = data[data['Environment'] == e_test]\n",
    "            X_test = test_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "            y_test = test_data[target_column]\n",
    "            \n",
    "            X_test_selected = selector.transform(X_test)\n",
    "            X_test_scaled = scaler.transform(X_test_selected)\n",
    "            \n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            r = np.sqrt(r2)\n",
    "            \n",
    "            # Get the selected feature names\n",
    "            selected_features = X_train.columns[selector.support_]\n",
    "            \n",
    "            # Store the results in the DataFrame\n",
    "            results_df.loc[len(results_df)] = [\"Lasso Regression\", target_column, e_train, e_test, mse, rmse, mae, r2, r, ','.join(selected_features)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_and_store_results(data, target_column, n_features=50):\n",
    "    for e_train in environments:\n",
    "        train_data = data[data['Environment'] == e_train]\n",
    "        \n",
    "        X_train = train_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "        y_train = train_data[target_column]\n",
    "        \n",
    "        # Feature selection using RFE\n",
    "        selector = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=n_features, step=10)\n",
    "        selector = selector.fit(X_train, y_train)\n",
    "        \n",
    "        # Select the important features\n",
    "        X_train_selected = selector.transform(X_train)\n",
    "        \n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "        \n",
    "        # Build and train the Support Vector Machine model\n",
    "        model = SVR()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate the model on other environments\n",
    "        for e_test in environments:\n",
    "            if e_test == e_train:\n",
    "                continue\n",
    "            \n",
    "            test_data = data[data['Environment'] == e_test]\n",
    "            X_test = test_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "            y_test = test_data[target_column]\n",
    "            \n",
    "            X_test_selected = selector.transform(X_test)\n",
    "            X_test_scaled = scaler.transform(X_test_selected)\n",
    "            \n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            r = np.sqrt(r2)\n",
    "            \n",
    "            # Get the selected feature names\n",
    "            selected_features = X_train.columns[selector.support_]\n",
    "            \n",
    "            # Store the results in the DataFrame\n",
    "            results_df.loc[len(results_df)] = [\"Support Vector Machine\", target_column, e_train, e_test, mse, rmse, mae, r2, r, ','.join(selected_features)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes_and_store_results(data, target_column, n_features=50):\n",
    "    for e_train in environments:\n",
    "        train_data = data[data['Environment'] == e_train]\n",
    "        \n",
    "        X_train = train_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "        y_train = train_data[target_column]\n",
    "        \n",
    "        # Feature selection using RFE\n",
    "        selector = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=n_features, step=10)\n",
    "        selector = selector.fit(X_train, y_train)\n",
    "        \n",
    "        # Select the important features\n",
    "        X_train_selected = selector.transform(X_train)\n",
    "        \n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "        \n",
    "        # Build and train the Naive Bayes model\n",
    "        model = GaussianNB()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate the model on other environments\n",
    "        for e_test in environments:\n",
    "            if e_test == e_train:\n",
    "                continue\n",
    "            \n",
    "            test_data = data[data['Environment'] == e_test]\n",
    "            X_test = test_data.drop(columns=[target_column, 'Environment', 'source_name'])\n",
    "            y_test = test_data[target_column]\n",
    "            \n",
    "            X_test_selected = selector.transform(X_test)\n",
    "            X_test_scaled = scaler.transform(X_test_selected)\n",
    "            \n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            r = np.sqrt(r2)\n",
    "            \n",
    "            # Get the selected feature names\n",
    "            selected_features = X_train.columns[selector.support_]\n",
    "            \n",
    "            # Store the results in the DataFrame\n",
    "            results_df.loc[len(results_df)] = [\"Naive Bayes\", target_column, e_train, e_test, mse, rmse, mae, r2, r, ','.join(selected_features)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP for th_positive_cells...\n",
      "Training environment: Earth\n",
      "Testing environment: Earth\n",
      "Testing environment: Earth\n",
      "Testing environment: Earth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1445/3663337175.py:45: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/3663337175.py:45: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training environment: SFug\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohinsood/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1445/3663337175.py:45: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing environment: SFug\n",
      "Testing environment: SFug\n",
      "Testing environment: SFug\n",
      "Training environment: SF1g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohinsood/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1445/3663337175.py:45: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/3663337175.py:45: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing environment: SF1g\n",
      "Testing environment: SF1g\n",
      "Testing environment: SF1g\n",
      "Training Linear Regression for th_positive_cells...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1445/3274056566.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/3274056566.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/3274056566.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/3274056566.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/3274056566.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/3274056566.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest for th_positive_cells...\n",
      "Training Ridge Regression for th_positive_cells...\n",
      "Training Lasso Regression for th_positive_cells...\n",
      "Training Support Vector Machine for th_positive_cells...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1445/50033032.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/50033032.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/50033032.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/50033032.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/50033032.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/50033032.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP for repo_glial_cells...\n",
      "Training environment: Earth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohinsood/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1445/3663337175.py:45: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing environment: Earth\n",
      "Testing environment: Earth\n",
      "Testing environment: Earth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1445/3663337175.py:45: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training environment: SFug\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohinsood/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing environment: SFug\n",
      "Testing environment: SFug\n",
      "Testing environment: SFug\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1445/3663337175.py:45: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training environment: SF1g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohinsood/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing environment: SF1g\n",
      "Testing environment: SF1g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1445/3663337175.py:45: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing environment: SF1g\n",
      "Training Linear Regression for repo_glial_cells...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1445/3274056566.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/3274056566.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/3274056566.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/3274056566.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/3274056566.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/3274056566.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest for repo_glial_cells...\n",
      "Training Ridge Regression for repo_glial_cells...\n",
      "Training Lasso Regression for repo_glial_cells...\n",
      "Training Support Vector Machine for repo_glial_cells...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1445/50033032.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/50033032.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/50033032.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/50033032.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/50033032.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n",
      "/tmp/ipykernel_1445/50033032.py:40: RuntimeWarning: invalid value encountered in sqrt\n",
      "  r = np.sqrt(r2)\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the models\n",
    "for target in target_columns:\n",
    "    print(f\"Training MLP for {target}...\")\n",
    "    train_MLP_and_store_results(df, target, n_features=2000)\n",
    "    print(f\"Training Linear Regression for {target}...\")\n",
    "    train_LR_and_store_results(df, target, n_features=2000)\n",
    "    print(f\"Training Random Forest for {target}...\")\n",
    "    train_RF_and_store_results(df, target, n_features=2000)\n",
    "    print(f\"Training Ridge Regression for {target}...\")\n",
    "    train_ridge_and_store_results(df, target, n_features=2000)\n",
    "    print(f\"Training Lasso Regression for {target}...\")\n",
    "    train_lasso_and_store_results(df, target, n_features=2000)\n",
    "    print(f\"Training Support Vector Machine for {target}...\")\n",
    "    train_svm_and_store_results(df, target, n_features=2000)\n",
    "\n",
    "results_csv_path = 'data/results/inv_n2000_all_model_results.csv'\n",
    "results_df.to_csv(results_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Target Variable</th>\n",
       "      <th>Training Environment</th>\n",
       "      <th>Test Environment</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>R</th>\n",
       "      <th>Selected Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>th_positive_cells</td>\n",
       "      <td>Earth</td>\n",
       "      <td>SFug</td>\n",
       "      <td>754070.086</td>\n",
       "      <td>868.372</td>\n",
       "      <td>560.952</td>\n",
       "      <td>-520.191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANN</td>\n",
       "      <td>th_positive_cells</td>\n",
       "      <td>Earth</td>\n",
       "      <td>SF1g</td>\n",
       "      <td>3347253.478</td>\n",
       "      <td>1829.550</td>\n",
       "      <td>938.194</td>\n",
       "      <td>-1294.885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANN</td>\n",
       "      <td>th_positive_cells</td>\n",
       "      <td>SFug</td>\n",
       "      <td>Earth</td>\n",
       "      <td>950.893</td>\n",
       "      <td>30.837</td>\n",
       "      <td>22.065</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.591</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANN</td>\n",
       "      <td>th_positive_cells</td>\n",
       "      <td>SFug</td>\n",
       "      <td>SF1g</td>\n",
       "      <td>840163.587</td>\n",
       "      <td>916.604</td>\n",
       "      <td>351.837</td>\n",
       "      <td>-324.268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANN</td>\n",
       "      <td>th_positive_cells</td>\n",
       "      <td>SF1g</td>\n",
       "      <td>Earth</td>\n",
       "      <td>2926.902</td>\n",
       "      <td>54.101</td>\n",
       "      <td>40.794</td>\n",
       "      <td>-1.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>repo_glial_cells</td>\n",
       "      <td>Earth</td>\n",
       "      <td>SF1g</td>\n",
       "      <td>156515.832</td>\n",
       "      <td>395.621</td>\n",
       "      <td>275.312</td>\n",
       "      <td>-0.901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>repo_glial_cells</td>\n",
       "      <td>SFug</td>\n",
       "      <td>Earth</td>\n",
       "      <td>32723.069</td>\n",
       "      <td>180.895</td>\n",
       "      <td>171.268</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>repo_glial_cells</td>\n",
       "      <td>SFug</td>\n",
       "      <td>SF1g</td>\n",
       "      <td>100230.258</td>\n",
       "      <td>316.592</td>\n",
       "      <td>269.745</td>\n",
       "      <td>-0.217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>repo_glial_cells</td>\n",
       "      <td>SF1g</td>\n",
       "      <td>Earth</td>\n",
       "      <td>40794.009</td>\n",
       "      <td>201.975</td>\n",
       "      <td>199.883</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>repo_glial_cells</td>\n",
       "      <td>SF1g</td>\n",
       "      <td>SFug</td>\n",
       "      <td>60771.821</td>\n",
       "      <td>246.519</td>\n",
       "      <td>230.189</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model    Target Variable Training Environment  \\\n",
       "0                       ANN  th_positive_cells                Earth   \n",
       "1                       ANN  th_positive_cells                Earth   \n",
       "2                       ANN  th_positive_cells                 SFug   \n",
       "3                       ANN  th_positive_cells                 SFug   \n",
       "4                       ANN  th_positive_cells                 SF1g   \n",
       "..                      ...                ...                  ...   \n",
       "157  Support Vector Machine   repo_glial_cells                Earth   \n",
       "158  Support Vector Machine   repo_glial_cells                 SFug   \n",
       "159  Support Vector Machine   repo_glial_cells                 SFug   \n",
       "160  Support Vector Machine   repo_glial_cells                 SF1g   \n",
       "161  Support Vector Machine   repo_glial_cells                 SF1g   \n",
       "\n",
       "    Test Environment         MSE     RMSE     MAE        R2     R  \\\n",
       "0               SFug  754070.086  868.372 560.952  -520.191   NaN   \n",
       "1               SF1g 3347253.478 1829.550 938.194 -1294.885   NaN   \n",
       "2              Earth     950.893   30.837  22.065     0.349 0.591   \n",
       "3               SF1g  840163.587  916.604 351.837  -324.268   NaN   \n",
       "4              Earth    2926.902   54.101  40.794    -1.002   NaN   \n",
       "..               ...         ...      ...     ...       ...   ...   \n",
       "157             SF1g  156515.832  395.621 275.312    -0.901   NaN   \n",
       "158            Earth   32723.069  180.895 171.268    -0.057   NaN   \n",
       "159             SF1g  100230.258  316.592 269.745    -0.217   NaN   \n",
       "160            Earth   40794.009  201.975 199.883    -0.317   NaN   \n",
       "161             SFug   60771.821  246.519 230.189    -0.022   NaN   \n",
       "\n",
       "                                     Selected Features  \n",
       "0    FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "1    FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "2    FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "3    FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "4    FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "..                                                 ...  \n",
       "157  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "158  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "159  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "160  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "161  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "\n",
       "[162 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Target Variable</th>\n",
       "      <th>Training Environment</th>\n",
       "      <th>Test Environment</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>R</th>\n",
       "      <th>Selected Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>th_positive_cells</td>\n",
       "      <td>SFug</td>\n",
       "      <td>Earth</td>\n",
       "      <td>56.499</td>\n",
       "      <td>7.517</td>\n",
       "      <td>4.440</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.980</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>th_positive_cells</td>\n",
       "      <td>SFug</td>\n",
       "      <td>Earth</td>\n",
       "      <td>57.921</td>\n",
       "      <td>7.611</td>\n",
       "      <td>4.473</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.980</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>th_positive_cells</td>\n",
       "      <td>SFug</td>\n",
       "      <td>Earth</td>\n",
       "      <td>58.743</td>\n",
       "      <td>7.664</td>\n",
       "      <td>4.516</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.980</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>th_positive_cells</td>\n",
       "      <td>SFug</td>\n",
       "      <td>Earth</td>\n",
       "      <td>59.051</td>\n",
       "      <td>7.684</td>\n",
       "      <td>4.521</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.980</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>th_positive_cells</td>\n",
       "      <td>SF1g</td>\n",
       "      <td>Earth</td>\n",
       "      <td>89.698</td>\n",
       "      <td>9.471</td>\n",
       "      <td>5.510</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.969</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>repo_glial_cells</td>\n",
       "      <td>Earth</td>\n",
       "      <td>SF1g</td>\n",
       "      <td>186723880669913097339910775373824.000</td>\n",
       "      <td>13664694678986176.000</td>\n",
       "      <td>5828179724546284.000</td>\n",
       "      <td>-2267510278425396538997997568.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>repo_glial_cells</td>\n",
       "      <td>SFug</td>\n",
       "      <td>SF1g</td>\n",
       "      <td>79796522345756902761268619771904.000</td>\n",
       "      <td>8932889921282860.000</td>\n",
       "      <td>6952820317595849.000</td>\n",
       "      <td>-969021391117437641521364992.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>repo_glial_cells</td>\n",
       "      <td>SF1g</td>\n",
       "      <td>Earth</td>\n",
       "      <td>66553810200900265479266608611328.000</td>\n",
       "      <td>8158051863092087.000</td>\n",
       "      <td>7350043296616467.000</td>\n",
       "      <td>-2149084290610453008156196864.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>repo_glial_cells</td>\n",
       "      <td>SF1g</td>\n",
       "      <td>SFug</td>\n",
       "      <td>274875405350486338449009274781696.000</td>\n",
       "      <td>16579366856140386.000</td>\n",
       "      <td>9790804230335650.000</td>\n",
       "      <td>-4621563404993952945488789504.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>repo_glial_cells</td>\n",
       "      <td>SFug</td>\n",
       "      <td>SF1g</td>\n",
       "      <td>805214867430253778613430502031360.000</td>\n",
       "      <td>28376308206499552.000</td>\n",
       "      <td>12514342557131088.000</td>\n",
       "      <td>-9778251082231501226877386752.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model    Target Variable Training Environment  \\\n",
       "14       Random Forest  th_positive_cells                 SFug   \n",
       "68       Random Forest  th_positive_cells                 SFug   \n",
       "50       Random Forest  th_positive_cells                 SFug   \n",
       "104      Random Forest  th_positive_cells                 SFug   \n",
       "70       Random Forest  th_positive_cells                 SF1g   \n",
       "..                 ...                ...                  ...   \n",
       "133  Linear Regression   repo_glial_cells                Earth   \n",
       "135  Linear Regression   repo_glial_cells                 SFug   \n",
       "136  Linear Regression   repo_glial_cells                 SF1g   \n",
       "137  Linear Regression   repo_glial_cells                 SF1g   \n",
       "27   Linear Regression   repo_glial_cells                 SFug   \n",
       "\n",
       "    Test Environment                                   MSE  \\\n",
       "14             Earth                                56.499   \n",
       "68             Earth                                57.921   \n",
       "50             Earth                                58.743   \n",
       "104            Earth                                59.051   \n",
       "70             Earth                                89.698   \n",
       "..               ...                                   ...   \n",
       "133             SF1g 186723880669913097339910775373824.000   \n",
       "135             SF1g  79796522345756902761268619771904.000   \n",
       "136            Earth  66553810200900265479266608611328.000   \n",
       "137             SFug 274875405350486338449009274781696.000   \n",
       "27              SF1g 805214867430253778613430502031360.000   \n",
       "\n",
       "                     RMSE                   MAE  \\\n",
       "14                  7.517                 4.440   \n",
       "68                  7.611                 4.473   \n",
       "50                  7.664                 4.516   \n",
       "104                 7.684                 4.521   \n",
       "70                  9.471                 5.510   \n",
       "..                    ...                   ...   \n",
       "133 13664694678986176.000  5828179724546284.000   \n",
       "135  8932889921282860.000  6952820317595849.000   \n",
       "136  8158051863092087.000  7350043296616467.000   \n",
       "137 16579366856140386.000  9790804230335650.000   \n",
       "27  28376308206499552.000 12514342557131088.000   \n",
       "\n",
       "                                   R2     R  \\\n",
       "14                              0.961 0.980   \n",
       "68                              0.960 0.980   \n",
       "50                              0.960 0.980   \n",
       "104                             0.960 0.980   \n",
       "70                              0.939 0.969   \n",
       "..                                ...   ...   \n",
       "133 -2267510278425396538997997568.000   NaN   \n",
       "135  -969021391117437641521364992.000   NaN   \n",
       "136 -2149084290610453008156196864.000   NaN   \n",
       "137 -4621563404993952945488789504.000   NaN   \n",
       "27  -9778251082231501226877386752.000   NaN   \n",
       "\n",
       "                                     Selected Features  \n",
       "14   FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "68   FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "50   FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "104  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "70   FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "..                                                 ...  \n",
       "133  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "135  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "136  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "137  FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "27   FBgn0000003,FBgn0000008,FBgn0000014,FBgn000001...  \n",
       "\n",
       "[162 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_results = results_df.copy().sort_values(by='MAE', ascending=True)\n",
    "sorted_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
